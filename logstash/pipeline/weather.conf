input { #filebeat로 data 파일 데이터 input
  beats {
    port => 5044
  }
}

filter {
  #twitter Api 실행시 나오는 문구는 저장하지 않음
  if [message] =~ "Starting new HTTPS" or [message] =~ "GET /2/tweets/search/stream HTTP/1.1"{
    drop { } 
  }
  #필요하지 않은 필드 삭제
  mutate {
    remove_field => ["tags", "log", "input", "agent","ecs", "@version", "event"]
  }

  #리트윗 텍스트 리트윗+아이디 부분 제거후 텍스트만 저장
  if [message] =~ "RT @"{
    #혹시 뒤에 url이 붙는 텍스트라면 url도 제거 
    if [message] =~ "https"{
      grok{
      match => {"message" => "(?<tmp1>RT+)\s@(?<tmp2>\w*):\s%{GREEDYDATA:data} %{URI:url}"}
      }
      mutate{
        remove_field => ["tmp1", "tmp2", "tmp3", "URI"]
      }  
    }
    #만약 url가 없는 데이터가 아니라면 그냥 저장
    else{
      grok{
        match => {"message" => "(?<tmp1>RT+)\s@(?<tmp2>\w*):\s%{GREEDYDATA:data}"}
      }
      mutate{
        remove_field => ["tmp1", "tmp2"]
      }
    }
  }
  #리트윗 데이터가 아니라면
  else{
    #혹시 뒤에 url이 붙는 텍스트라면 url 제거
    if [message] =~ "https"{
      grok {
        match => {"message" => "%{GREEDYDATA:data} %{URI:url}"}
      }
      mutate{
        remove_field => ["tmp1", "url"]
      }
    }
    #아무것도 해당되지 않으면 그냥 저장
    else{
      grok {
        match => {"message" => "%{GREEDYDATA:data}"}
      }
    }
    #리트윗 데이터가 아니여도 @아이디 형식으로 시작되는 텍스트 @아이디 삭제
    if [message] =~ "@"{
      grok{
        match => {"message" => "@(?<tmp>\w*)\s%{GREEDYDATA:data}"}
      }
      mutate{
        remove_field => ["tmp"]
      }
    }
  }
  #word cloud를 구현하기 위해서 token_data 필드 생성
  grok{
    match => {"data" => "%{GREEDYDATA:token_data}"}
  }
  #중복방지를 위해서 각각의 데이터에 대한 fingerprint생성
  fingerprint {
    method => "SHA1"
    source => "data"
    target => "fingerprint"
  }
  #한국시간 kr_time필드에 저장
  ruby{ 
    code => "event.set('kr_time', LogStash::Timestamp.new(event.get('@timestamp')+(9*60*60)))"
  }
  #현재 날짜 kr_date 파일에 저장
  ruby{
    code => "event.set('kr_date', event.get('@timestamp').time.localtime('+09:00').strftime('%Y%m%d'))"
  }

}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "weather-%{kr_date}" #weather-날짜로 인덱스 저장
    template => "/usr/share/logstash/templates/weather.json" #템플릿 파일 위치
    template_name => "weather" #템플릿 이름 weather로 설정
    document_id => "%{fingerprint}" #도큐먼트 아이디를 fingerprint로 하여 중복 제거
    pipeline => "kr_sentiment" #elasticsearch ingest pipeline 실행
  }
}
